#!/usr/bin/env python3
"""
Visualize a single CIFAR-10 sample together with ResNet predictions.
Loads the checkpoint generated by train_resnet_cifar.py, runs inference,
and saves/displays the image annotated with ground-truth + top-k outputs.
"""
from __future__ import annotations

import argparse
import json
import random
from pathlib import Path
from typing import Dict, Tuple

import matplotlib
import matplotlib.pyplot as plt
import torch
from PIL import Image
from torchvision import datasets

try:
    import timm
    from timm.data import create_transform
except ImportError as err:
    raise SystemExit(
        "timm is required for this script. Install it with `pip install timm`."
    ) from err

IMAGENET_MEAN = (0.485, 0.456, 0.406)
IMAGENET_STD = (0.229, 0.224, 0.225)
CIFAR10_CLASSES = [
    "airplane",
    "automobile",
    "bird",
    "cat",
    "deer",
    "dog",
    "frog",
    "horse",
    "ship",
    "truck",
]


def parse_args() -> argparse.Namespace:
    parser = argparse.ArgumentParser(description="Show CIFAR-10 prediction example")
    parser.add_argument(
        "--config",
        default="runs/resnet_ft/config.json",
        help="config.json produced by train_resnet_cifar.py",
    )
    parser.add_argument(
        "--checkpoint",
        default="runs/resnet_ft/best.pt",
        help="checkpoint (.pt) to load",
    )
    parser.add_argument(
        "--split",
        choices=["train", "test"],
        default="test",
        help="dataset split to sample from",
    )
    parser.add_argument(
        "--index",
        type=int,
        default=-1,
        help="sample index (negative -> random)",
    )
    parser.add_argument(
        "--seed",
        type=int,
        default=0,
        help="random seed for sampling",
    )
    parser.add_argument(
        "--topk",
        type=int,
        default=3,
        help="number of top predictions to display",
    )
    parser.add_argument(
        "--output",
        default=None,
        help="optional path to save annotated image (PNG). Defaults next to checkpoint.",
    )
    parser.add_argument(
        "--device",
        default="cuda",
        help="device to run inference on",
    )
    parser.add_argument(
        "--safe",
        action="store_true",
        help="force Agg backend to avoid GUI (useful in headless WSL)",
    )
    return parser.parse_args()


def ensure_backend(use_safe: bool) -> None:
    if use_safe:
        matplotlib.use("Agg")


def load_config(path: Path) -> Dict:
    with open(path, "r", encoding="utf-8") as f:
        return json.load(f)


def build_transform(cfg: Dict):
    img_size = int(cfg.get("img_size", 224))
    interpolation = cfg.get("interpolation", "bicubic")
    return create_transform(
        is_training=False,
        input_size=(3, img_size, img_size),
        mean=IMAGENET_MEAN,
        std=IMAGENET_STD,
        interpolation=interpolation,
    )


def load_dataset(cfg: Dict, split: str) -> datasets.CIFAR10:
    data_dir = cfg.get("data_dir", "./data")
    is_train = split == "train"
    dataset = datasets.CIFAR10(
        root=data_dir,
        train=is_train,
        download=True,
        transform=None,
    )
    return dataset


def pick_sample(dataset: datasets.CIFAR10, index: int, seed: int) -> Tuple[Image.Image, int, int]:
    if index < 0 or index >= len(dataset):
        random.seed(seed)
        index = random.randrange(len(dataset))
    image, label = dataset[index]
    return image, label, index


def create_model_from_config(cfg: Dict) -> torch.nn.Module:
    model_name = cfg.get("model", "resnet18")
    num_classes = int(cfg.get("num_classes", 10))
    model = timm.create_model(model_name, pretrained=False, num_classes=num_classes)
    return model


def annotate_axes(ax, pil_img: Image.Image, label: str, top_preds: str) -> None:
    ax.imshow(pil_img)
    ax.axis("off")
    ax.set_title(f"GT: {label}\n{top_preds}", fontsize=12)


def main() -> None:
    args = parse_args()
    ensure_backend(args.safe)

    config_path = Path(args.config).expanduser()
    checkpoint_path = Path(args.checkpoint).expanduser()
    if not config_path.exists():
        raise FileNotFoundError(f"Config file not found: {config_path}")
    if not checkpoint_path.exists():
        raise FileNotFoundError(f"Checkpoint not found: {checkpoint_path}")

    cfg = load_config(config_path)
    transform = build_transform(cfg)
    dataset = load_dataset(cfg, args.split)
    pil_img, gt_label_idx, chosen_idx = pick_sample(dataset, args.index, args.seed)

    device = torch.device(args.device if torch.cuda.is_available() else "cpu")
    model = create_model_from_config(cfg).to(device)
    checkpoint = torch.load(checkpoint_path, map_location=device)
    state_dict = checkpoint.get("model", checkpoint)
    model.load_state_dict(state_dict)
    model.eval()

    input_tensor = transform(pil_img).unsqueeze(0).to(device)
    with torch.no_grad():
        logits = model(input_tensor)
        probs = torch.softmax(logits, dim=1)
        topk = min(args.topk, probs.shape[1])
        conf, idxs = torch.topk(probs, k=topk, dim=1)

    gt_label = CIFAR10_CLASSES[gt_label_idx]
    lines = []
    for rank in range(topk):
        cls_idx = idxs[0, rank].item()
        cls_name = CIFAR10_CLASSES[cls_idx]
        conf_pct = conf[0, rank].item() * 100
        lines.append(f"Top{rank+1}: {cls_name} ({conf_pct:.1f}%)")
    topk_text = "\n".join(lines)

    print(f"Sample index: {chosen_idx} | Ground truth: {gt_label}")
    for line in lines:
        print(line)

    fig, ax = plt.subplots(figsize=(4, 4))
    annotate_axes(ax, pil_img, gt_label, topk_text)
    fig.tight_layout()

    if args.output:
        output_path = Path(args.output).expanduser()
    else:
        output_name = f"{checkpoint_path.parent.name}_sample_{chosen_idx}.png"
        output_path = checkpoint_path.with_name(output_name)
    fig.savefig(output_path, dpi=200, bbox_inches="tight")
    print(f"Saved annotated sample to {output_path}")

    if not args.safe:
        try:
            plt.show()
        except Exception as exc:  # pragma: no cover
            print(f"Could not open GUI window ({exc}). Figure saved to {output_path}.")


if __name__ == "__main__":
    main()
